üßæ IMPORTS
python
Copy
Edit
import numpy as np, random
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
numpy (np) is used for array operations and generating random numbers.

random is used for Python‚Äôs native random functions (e.g., crossover/mutation).

MLPRegressor is a neural network for regression tasks.

mean_squared_error is used to evaluate prediction error.

train_test_split divides the dataset into training and testing sets.

üî¢ DATA GENERATION & PREPARATION
python
Copy
Edit
np.random.seed(42)
Sets the random seed for reproducibility.

python
Copy
Edit
X = (np.random.uniform(150, 200, (100, 3)) - 175) / 25
Creates a dataset X of shape (100, 3) with values in [150, 200].

Then shifts to center around 0 by subtracting 175.

Scales it to approximately [-1, 1] by dividing by 25.

This normalization helps NN training.

python
Copy
Edit
y = 0.3*X[:,0] - 0.2*X[:,1] + 0.1*X[:,2] + np.random.normal(0, 2, 100)
y is a linear combination of the input features + noise.

np.random.normal(0, 2, 100) adds Gaussian noise (mean=0, std=2).

python
Copy
Edit
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
Splits data: 80 samples for training, 20 for testing.

üß† FUNCTION: Create a Neural Network with Custom Weights
python
Copy
Edit
def create_nn(params):
Defines a function to create a neural network using manually provided weights.

python
Copy
Edit
    m = MLPRegressor(hidden_layer_sizes=(5,), max_iter=100, solver='lbfgs', warm_start=True)
Initializes an MLP with:

1 hidden layer of 5 neurons

max_iter=100: max 100 iterations of training

solver='lbfgs': a quasi-Newton optimizer

warm_start=True: allows updating weights without reinitializing.

python
Copy
Edit
    m.fit(X_train, y_train)
Trains the model (needed to initialize weight structures: coefs_, intercepts_).

python
Copy
Edit
    p = np.array(params); i = 0
Converts params (list of weights) to NumPy array.

i will track index while assigning weights.

python
Copy
Edit
    for arr in m.coefs_ + m.intercepts_:
Iterates over all weight arrays: input-to-hidden weights, hidden-to-output weights, and biases.

python
Copy
Edit
        s = np.prod(arr.shape)
s: number of values needed for this layer's weights/biases.

python
Copy
Edit
        arr[...] = p[i:i+s].reshape(arr.shape)
Replaces current layer's weights with the corresponding slice of p.

python
Copy
Edit
        i += s
Move to the next set of weights in params.

python
Copy
Edit
    return m
Returns the customized model.

üìè FUNCTION: Fitness (MSE) Calculation
python
Copy
Edit
def fitness(p): 
    return mean_squared_error(y_train, create_nn(p).predict(X_train))
Measures how well the model (with given weights p) predicts training data.

Lower MSE = better fitness.

üîÄ FUNCTION: Crossover (Combining Parents)
python
Copy
Edit
def crossover(p1, p2): 
    pt = random.randint(0, len(p1)-1)
    return p1[:pt] + p2[pt:]
Picks a random crossover point pt.

Combines the first part of p1 and the second part of p2 to make a new individual.

üß¨ FUNCTION: Mutation (Add Random Noise)
python
Copy
Edit
def mutate(p, r=0.1): 
    return [w+np.random.randn()*r if random.random()<0.1 else w for w in p]
Each weight w has a 10% chance of being mutated.

If mutated, Gaussian noise is added (r is mutation strength, default = 0.1).

üß™ INITIALIZATION: Neural Network and GA Setup
python
Copy
Edit
tmp = MLPRegressor(hidden_layer_sizes=(5,), max_iter=100)
tmp.fit(X_train, y_train)
A temporary model is trained to determine the total number of weights + biases.

python
Copy
Edit
n_params = sum(np.prod(a.shape) for a in tmp.coefs_ + tmp.intercepts_)
Calculates the total number of parameters (weights and biases) needed.

üå± INITIAL POPULATION
python
Copy
Edit
pop = [np.random.uniform(-1, 1, n_params).tolist() for _ in range(10)]
Creates a population of 10 individuals (solutions).

Each individual is a list of n_params random values in [-1, 1].

üìà MAIN EVOLUTION LOOP
python
Copy
Edit
mse_per_gen = []
Stores best MSE of each generation for later display.

python
Copy
Edit
for g in range(10):
Run for 10 generations.

python
Copy
Edit
    pop = sorted(pop, key=fitness)
Sorts individuals based on fitness (lower MSE is better).

python
Copy
Edit
    best_mse = fitness(pop[0])
Gets the MSE of the best individual.

python
Copy
Edit
    mse_per_gen.append(best_mse)
Saves this MSE for plotting later.

python
Copy
Edit
    print(f"Gen {g+1}, MSE: {best_mse:.4f}")
Outputs the generation number and best MSE.

üß¨ CREATE NEW GENERATION
python
Copy
Edit
    new_pop = pop[:2]
Keep top 2 individuals (elitism).

python
Copy
Edit
    while len(new_pop) < len(pop):
        c = mutate(crossover(*random.sample(pop[:5], 2)))
        new_pop.append(c)
Until the population is full again:

Pick 2 parents from top 5.

Cross them to create a child.

Mutate the child.

Add child to new population.

python
Copy
Edit
    pop = new_pop
Replace old population with new one.

üìä FINAL RESULTS
python
Copy
Edit
print("\nMSE per Generation:")
Print header

python
Copy
Edit
for i, mse in enumerate(mse_per_gen, 1):
    print(f"Generation {i}: MSE = {mse:.4f}")
Show MSE progression over generations.

‚úÖ Summary
What this code does:
Creates a synthetic regression problem.

Trains a neural network using a genetic algorithm by:

Randomly initializing weights

Evaluating MSE

Performing crossover + mutation

Evolving over generations

Why it's interesting:
Shows how you can optimize a neural network without gradient descent.

Illustrates evolutionary computation concepts like mutation, crossover, fitness evaluation, and elitism.


THEORY: Genetic Algorithm-based Neural Network Training
üîπ Introduction
Traditional neural networks are trained using gradient descent algorithms, which adjust weights based on calculated gradients. However, genetic algorithms (GAs) provide an alternative training method that does not require differentiability, making them useful for:

Black-box models

Complex, noisy, or non-continuous loss functions

Global optimization

üîπ What is a Genetic Algorithm?
A Genetic Algorithm (GA) is a biologically-inspired optimization algorithm based on:

GA Concept	Biological Analogy
Population	Group of individuals (solutions)
Chromosome	A candidate solution
Fitness function	Quality or performance score
Crossover	Breeding between parents
Mutation	Random change in offspring
Selection	Prefer better solutions
Generation	Iteration over population

üîπ How Neural Networks are Trained Using GA
Instead of using backpropagation, GA evolves neural network weights:

Encode Weights: Flatten weights + biases into a 1D vector (chromosome).

Fitness Function: Use mean squared error (MSE) as a score.

Initial Population: Generate random weight sets.

Selection: Choose best-performing chromosomes.

Crossover: Combine parents' weights to create children.

Mutation: Slightly alter some weights randomly.

Replacement: Form a new generation.

Repeat for several generations.

üîπ Advantages of GA in Neural Networks
Works for non-differentiable loss functions

Can escape local minima

No need for derivative computation

Flexible and modular

üîπ Disadvantages
Slower convergence compared to backpropagation

Computationally expensive

Often needs more generations and population size to reach optimality

üìò EXAM-STYLE QUESTIONS AND ANSWERS
üî∏ Q1. What is the role of genetic algorithms in training a neural network?
Answer:
Genetic Algorithms (GAs) are used to optimize the weights and biases of neural networks without relying on gradient-based methods. In this approach, a population of weight sets is evolved using operations like crossover and mutation. The fitness of each solution is evaluated using a metric like mean squared error. Over multiple generations, the algorithm selects better solutions, combines them, and introduces diversity via mutation, ultimately converging to an optimized neural network.

üî∏ Q2. Explain how weights are represented and manipulated in this GA-based neural network.
Answer:
The neural network's weights and biases are flattened into a single list (chromosome). This list becomes the GA individual's genome. The create_nn() function maps these flattened weights back into the network‚Äôs internal weight structure (coefs_ and intercepts_). During evolution, these genomes are crossed over and mutated to create new candidates, which are evaluated using the fitness function.

üî∏ Q3. Why is the .fit() method called before assigning weights manually in create_nn()?
Answer:
The .fit() method is necessary to initialize the internal structure of the MLPRegressor, especially the shapes of coefs_ and intercepts_. These attributes do not exist before training begins. Once initialized, we can safely overwrite them with custom weights from our chromosome (i.e., params).

üî∏ Q4. What is the fitness function in this program, and why is it important?
Answer:
The fitness function in this program is the mean squared error (MSE) on the training dataset:

python
Copy
Edit
def fitness(p): 
    return mean_squared_error(y_train, create_nn(p).predict(X_train))
It measures how well the neural network (created using weights p) performs on the training data. Lower MSE indicates a better model, and hence better fitness. This value guides the genetic algorithm in selecting and generating better solutions.

üî∏ Q5. Describe the role of mutation in genetic algorithms and how it is implemented here.
Answer:
Mutation introduces randomness into the population, helping the GA escape local minima and maintain diversity. In this code:

python
Copy
Edit
def mutate(p, r=0.1): 
    return [w + np.random.randn()*r if random.random() < 0.1 else w for w in p]
Each weight has a 10% chance of being modified by adding a small random Gaussian value (r controls its range). This keeps the population from becoming too similar and improves exploration of the search space.

üî∏ Q6. What is elitism in genetic algorithms? How is it used in this code?
Answer:
Elitism means carrying forward the best-performing individuals directly to the next generation to preserve good solutions. In this code:

python
Copy
Edit
new_pop = pop[:2]
The top 2 individuals (lowest MSE) are copied directly into the new population, ensuring that their information is not lost during crossover and mutation.

üî∏ Q7. Compare backpropagation and genetic algorithm-based training.
Feature	Backpropagation	Genetic Algorithm
Requires Gradient	Yes	No
Convergence Speed	Faster	Slower
Local Minima Risk	High	Lower (can escape)
Robustness	Sensitive to learning rate	More robust to hyperparameters
Parallelization	Less natural	Naturally parallelizable
Usage	Standard training method	Used in complex or noisy fitness landscapes

üî∏ Q8. How does crossover help in optimizing neural network weights?
Answer:
Crossover simulates sexual reproduction by combining two parents' weights (genomes) into a child. This allows the child to inherit strengths from both parents, promoting diversity and better solutions. In this code:

python
Copy
Edit
def crossover(p1, p2): 
    pt = random.randint(0, len(p1)-1)
    return p1[:pt] + p2[pt:]
A random crossover point pt is chosen, and the child receives weights from p1 up to pt, and from p2 after pt.

üî∏ Q9. What is the role of the warm_start=True parameter in the MLPRegressor?
Answer:
warm_start=True allows the model to retain its weights between calls to .fit() or successive training sessions. However, in this code, it has limited impact, since we replace the weights manually right after .fit() is called. Still, it prevents reinitialization if used iteratively.

üî∏ Q10. What are some limitations of using genetic algorithms for training neural networks?
Answer:

Slow convergence: Takes many generations and large populations.

Computationally expensive: Especially for large networks.

Hard to fine-tune: GA hyperparameters (mutation rate, selection strategy) are tricky.

No gradient usage: Slower improvement compared to gradient-based learning in many cases.